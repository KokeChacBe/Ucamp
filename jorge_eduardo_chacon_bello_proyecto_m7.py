# -*- coding: utf-8 -*-
"""Jorge Eduardo Chacon Bello Proyecto M7

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yZSrFHQZe7echW_gSwIQhVXLyxhV7pXg

## **Bootcamp: Ciencia de Datos e Inteligencia Artificial**
## **Proyecto del Módulo 7: Técnicas avanzadas para ciencia de datos y empleabilidad**

Hola, ya es el último proyecto, has avanzado y aprendido mucho hasta acá. ¡Muchas felicidades!

Es hora de poner en práctica todo lo que hemos aprendido a lo largo de nuestra travesía.

Lee el proyecto y revisa con cuidado cada una de las instrucciones. Procura plasmar todo tu potencial para que lo concluyas de manera sobresaliente.

¡Éxito!

# Objetivos
- Aplicar con éxito todos los conocimientos que has adquirido a lo largo del Bootcamp.
- Consolidar las técnicas de limpieza, entrenamiento, graficación y ajuste a modelos de *Machine Learning*.
- Generar una API que brinde predicciones como resultado a partir de datos enviados.

# Proyecto

1. Selecciona uno de los siguientes *datasets*:
  - Imágenes de rayos X de pecho para detectar neumonía: https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia
  - *Reviews* de aplicaciones de la Google Play Store: https://www.kaggle.com/datasets/lava18/google-play-store-apps
  - Estadísticas demográficas de los ganadores del premio Oscar de la Academia: https://www.kaggle.com/datasets/fmejia21/demographics-of-academy-awards-oscars-winners
  - Aspiraciones profesionales de la generación Z: https://www.kaggle.com/datasets/kulturehire/understanding-career-aspirations-of-genz

Cada uno representa un *dataset*, un problema y una forma diferente de abordarlo. Tu tarea es identificar las técnicas y modelos que podrías usar para tu proyecto.

2. Debes hacer un análisis exploratorio y limpieza de los datos. Usa las ténicas que creas convenientes.

3. Entrena el modelo de *Machine Learning*, procesamiento de lenguaje natural o red neuronal que creas adecuado.

4. Genera por lo menos dos gráficas y dos métricas de rendimiento; explica las puntuaciones de rendimiento que amerite tu problema. Todas las gráficas de rendimiento que realices deben tener leyendas, colores y títulos personalizados por ti. 

  - Además, antes de subir el modelo a "producción", deberás realizar un proceso de ensambles (*ensemblings*) y de ajuste de hiperparámetros o *tuning* para intentar mejorar la precisión y disminuir la varianza de tu modelo.

5. Construye una API REST en la que cualquier usuario pueda mandar datos y que esta misma devuelva la predicción del modelo que has hecho. La API debe estar en la nube, ya sea en un servicio como Netlify o Ngrok, para que pueda ser consultada desde internet.

6. Genera una presentación del problema y del modelo de solución que planteas. Muestra gráficas, datos de rendimiento y explicaciones. Esta presentación debe estar enfocada a personas que no sepan mucho de ciencia de datos e inteligencia artificial.

7. **Solamente se recibirán trabajos subidos a tu cuenta de GitHub con un README.md apropiado que explique tu proyecto**. 

## Criterios de evaluación

| Actividad | Porcentaje | Observaciones | Punto parcial
| -- | -- | -- | -- |
| Actividad 1. Limpieza y EDA | 20 | Realiza todas las tareas necesarias para hacer el EDA y la limpieza correcta, dependiendo de la problemática. Debes hacer como mínimo el análisis de completitud, escalamiento (si aplica) y tokenización (si aplica). | Realizaste solo algunas tareas de exploración y limpieza y el modelo se muestra aún con oportunidad de completitud, escalamiento y/o mejora. |
| Actividad 2. Entrenamiento del modelo | 20 | Elige el modelo y algoritmo adecuados para tu problema, entrénalo con los datos ya limpios y genera algunas predicciones de prueba. | No has realizado predicciones de prueba para tu modelo de ML y/o tu modelo muestra una precisión menor al 60 %. |
| Actividad 3. Graficación y métricas | 20 | Genera por lo menos dos gráficas y dos muestras de métricas que permitan visualizar el rendimiento y precisión del modelo que construiste. Además, realizaste los procesos de *tuning* y ensambles adecuados para tu problema. | Las gráficas no tienen leyendas y colores customizados, solo muestras una gráfica o no realizaste el *tuning* de hiperparámetros.
| Actividad 4. API REST | 20 | Generaste con éxito un *link* público en el que, por método POST, se puede mandar información y la API REST devuelve una predicción junto con el porcentaje de confianza de esta misma. | N/A
| Actividad 5. Presentación | 20 | Genera una presentación en la que establezcas como mínimo: el problema, proceso de solución, metodologías usadas, gráficas de rendimiento, demostración del modelo y aprendizajes obtenidos. Debes redactarla con términos que pueda entender cualquier persona, no solo científicos de datos. | La presentación no expone con claridad o en términos coloquiales el proceso de creación del modelo, sus ventajas y muestras de rendimiento.

**Mucho éxito en tu camino como Data Scientist.**

1 Datos seleccionados: La base de datos de google play

Predicción de la calidad de las aplicaciones: con el machine learning, se pueden construir modelos para predecir la calificación de una aplicación en función de sus características. Esto puede ayudar a los desarrolladores a identificar áreas de mejora para sus aplicaciones y mejorar la calidad general de las aplicaciones en la tienda Google Play.
"""

from google.colab import drive
drive.mount('/content/drive')

# Importar librerías necesarias
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import LabelEncoder
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import RandomizedSearchCV
import seaborn as sns
import matplotlib.pyplot as plt

import pandas as pd
import numpy as np

df = pd.read_csv('/content/drive/MyDrive/Ucamp/googleplaystore.csv')
df.head(5)

# Eliminar filas duplicadas
df.drop_duplicates(inplace=True)

# Eliminar filas con valores faltantes
df.dropna(inplace=True)

# Convertir la variable 'Price' a numérica
df['Price'] = df['Price'].apply(lambda x: str(x).replace('$', '') if '$' in str(x) else str(x))
df['Price'] = df['Price'].apply(lambda x: float(x))

# Convertir la variable 'Installs' a numérica
df['Installs'] = df['Installs'].apply(lambda x: str(x).replace('+', '') if '+' in str(x) else str(x))
df['Installs'] = df['Installs'].apply(lambda x: str(x).replace(',', '') if ',' in str(x) else str(x))
df['Installs'] = df['Installs'].apply(lambda x: int(x))

# Convertir la variable 'Reviews' a numérica
df['Reviews'] = df['Reviews'].astype(int)

# Convertir la variable 'Size' a numérica

# Reemplazar "Varies with device" y valores similares con 0
df['Size'] = df['Size'].apply(lambda x: str(x).replace('Varies with device', '0') if 'Varies with device' in str(x) else str(x))

# Eliminar la letra "k" de los valores
df['Size'] = df['Size'].apply(lambda x: str(x).replace('k', '') if 'k' in str(x) else str(x))

# Convertir los valores a números de punto flotante, y utilizar NaN para los valores que no se puedan convertir
df['Size'] = pd.to_numeric(df['Size'], errors='coerce')

# Reemplazar los valores NaN con la mediana de la columna "Size"
df['Size'].fillna((df['Size'].median()), inplace=True)


# Codificar la variable 'Content Rating'
le = LabelEncoder()
df['Content Rating'] = le.fit_transform(df['Content Rating'])

# Seleccionar las variables predictoras y la variable objetivo
X = df[['Category', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating']]
y = df['Rating']

# Codificar las variables categóricas
X = pd.get_dummies(X, columns=['Category', 'Type'])

# Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Crear el modelo de regresión lineal
reg = LinearRegression()

# Entrenar el modelo
reg.fit(X_train, y_train)

# Realizar la predicción
y_pred = reg.predict(X_test)

# Evaluar el modelo
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)
print('RMSE:', rmse)
print('R2:', r2)

print('RMSE:', rmse)
print('R2:', r2)

"""Se puede observar que el MSE obtenido es relativamente bajo, lo que indica que el modelo tiene un buen rendimiento en general. Además, el valor de R2 obtenido indica que el modelo explica una buena cantidad de la varianza en la variable de calificación. Sin embargo, siempre es importante tener en cuenta el contexto del problema y evaluar si estos valores son suficientes para la aplicación en cuestión. Por ejemplo, en una aplicación donde la precisión en la predicción de la calificación es crítica, se podrían requerir valores más altos de MSE y R2 para considerar el modelo como adecuado."""

#Graficas
# Gráfica 1: Comparación de valores reales vs. predichos
plt.scatter(y_test, y_pred)
plt.xlabel('Valor real')
plt.ylabel('Valor predicho')
plt.title('Comparación de valores reales vs. predichos')
plt.show()

# Gráfica 2: Distribución de errores
sns.histplot(y_test - y_pred)
plt.xlabel('Error')
plt.ylabel('Frecuencia')
plt.title('Distribución de errores')
plt.show()

#Ensamble y ajustes

# Eliminar filas duplicadas
df.drop_duplicates(inplace=True)

# Eliminar filas con valores faltantes
df.dropna(inplace=True)

# Convertir la variable 'Price' a numérica
df['Price'] = df['Price'].apply(lambda x: str(x).replace('$', '') if '$' in str(x) else str(x))
df['Price'] = df['Price'].apply(lambda x: float(x))

# Convertir la variable 'Installs' a numérica
df['Installs'] = df['Installs'].apply(lambda x: str(x).replace('+', '') if '+' in str(x) else str(x))
df['Installs'] = df['Installs'].apply(lambda x: str(x).replace(',', '') if ',' in str(x) else str(x))
df['Installs'] = df['Installs'].apply(lambda x: int(x))

# Convertir la variable 'Reviews' a numérica
df['Reviews'] = df['Reviews'].astype(int)

# Convertir la variable 'Size' a numérica

# Reemplazar "Varies with device" y valores similares con 0
df['Size'] = df['Size'].apply(lambda x: str(x).replace('Varies with device', '0') if 'Varies with device' in str(x) else str(x))

# Eliminar la letra "k" de los valores
df['Size'] = df['Size'].apply(lambda x: str(x).replace('k', '') if 'k' in str(x) else str(x))

# Convertir los valores a números de punto flotante, y utilizar NaN para los valores que no se puedan convertir
df['Size'] = pd.to_numeric(df['Size'], errors='coerce')

# Reemplazar los valores NaN con la mediana de la columna "Size"
df['Size'].fillna((df['Size'].median()), inplace=True)


# Codificar la variable 'Content Rating'
le = LabelEncoder()
df['Content Rating'] = le.fit_transform(df['Content Rating'])

# Seleccionar las variables predictoras y la variable objetivo
X = df[['Category', 'Reviews', 'Size', 'Installs', 'Type', 'Price', 'Content Rating']]
y = df['Rating']

# Codificar las variables categóricas
X = pd.get_dummies(X, columns=['Category', 'Type'])

# Dividir los datos en entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Definir el modelo de regresión
rf = RandomForestRegressor()

# Definir la distribución de hiperparámetros para probar
param_dist = {
    "n_estimators": [100, 200, 300, 400, 500],
    "max_depth": [10, 20, 30, 40, 50],
    "min_samples_split": [2, 4, 6, 8, 10],
    "min_samples_leaf": [1, 2, 4, 8, 16],
}

# Definir la búsqueda aleatoria con validación cruzada
rrandom_search = RandomizedSearchCV(
    estimator=rf,
    param_distributions=param_dist,
    n_iter=20,
    cv=5,
    verbose=2,
    n_jobs=-1,
    random_state=42,
    error_score='raise'  # Agregar el parámetro error_score='raise'
)


# Ajustar la búsqueda aleatoria al conjunto de datos de entrenamiento
random_search.fit(X_train, y_train)

# Imprimir el mejor conjunto de hiperparámetros y el score
print("Best params: ", random_search.best_params_)
print("Best score: ", -random_search.best_score_)

# Utilizar el modelo con los mejores hiperparámetros para hacer predicciones en el conjunto de prueba
y_pred = random_search.predict(X_test)

# Calcular las métricas de rendimiento
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Imprimir las métricas de rendimiento
print("MSE: ", mse)
print("R2: ", r2)

"""Los nuevos resultados del MSE y R2 son significativamente mejores que los anteriores, lo que indica que el modelo ha mejorado su capacidad para ajustarse a los datos y hacer predicciones precisas. El MSE indica que el modelo tiene un error cuadrático medio de aproximadamente 0.23, lo que significa que las predicciones del modelo en promedio difieren de los valores reales en 0.23 unidades al cuadrado. El R2 indica que el modelo explica aproximadamente el 15% de la variabilidad en los datos, lo cual no es muy alto, pero es una mejora significativa en comparación con los resultados anteriores.

En resumen, los nuevos resultados indican que el modelo ha mejorado su capacidad para ajustarse a los datos y hacer predicciones precisas, y que tiene un rendimiento significativamente mejor que los resultados anteriores.
"""

#Graficas con los ajustes
# Gráfica 1: Comparación de valores reales vs. predichos
plt.scatter(y_test, y_pred, color='purple')
plt.xlabel('Valor real')
plt.ylabel('Valor predicho')
plt.title('Comparación de valores reales vs. predichos')
plt.show()

# Gráfica 2: Distribución de errores
sns.histplot(y_test - y_pred, color='purple')
plt.xlabel('Error')
plt.ylabel('Frecuencia')
plt.title('Distribución de errores')
plt.show()